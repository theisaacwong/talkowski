---
title: "gCNV pre and post processing"
output: html_document
author: Isaac Wong
version: 2.21
---



To begin, load the required packages and some functions
```{r}
source("C:/Users/iwong/OneDrive/R/my_libraries.R")
```

This workflow is an attempt to provide instructions on running gCNV. Please let me know of any isses you run into or any processes you want improved/automated. Please ensure you have downloaded the most recent files from my github: https://github.com/theisaacwong/talkowski/tree/master/gCNV. You should be able to run the pipeline chunk by chunk.

# Step 1
run gatk CollectReadCounts on each sample using the `aux_capture_uniques_hg38_chr_sorted` and `gencode_v33_split_800` intervals
```{}
        gatk --java-options "-Xmx${command_mem_mb}m" CollectReadCounts \
            -I ${cram} \
            --read-index ${crai} \
            -L ${intervals_barcode} \
            --interval-merging-rule OVERLAPPING_ONLY \
            --reference ${hg38_reference} \
            --format TSV \
            -O ${counts_barcode_filename}
```


#Step 2
Download the barcode counts files to the wd. If the column name in your manifest file isn't "counts_barcode" then change code. This chunk just makes a system call to run the jar, which itself makes a system call to gsutil to download the files. It's turtles all the way down. 
```{r}
wd <- "/path/to/folder/"
system2("java", sprintf("-Xmx16G -jar %s getBarcodeCounts %ssample_set_entity.tsv %s counts_barcode", jar_path, wd, wd ))
```

#Step 3
Convert the barcode count files into a matrix file where rows are samples and columns are intervals
```{r}
wd <- "/path/to/folder/"
system2("java", sprintf("-Xmx16G -jar %s getCountsMatrix %s %scounts_matrix.tsv .barcode.counts.tsv", jar_path, wd, wd ))
```

#Step 4
- perform data normalization
- remove x and y chromosomes
- perform PCA
- save the R PCA object
a scree plot for the PCA loadings is generated to help visualize the data. 
```{r}
wd <- ""
counts_df <- read.table(paste0(wd, "counts_matrix.tsv"), sep="\t", stringsAsFactors = FALSE, header=TRUE, fill=TRUE)

counts_df[is.na(counts_df)] <- 0
counts_matrix <- t(as.matrix(counts_df))
indexes_to_remove <- rep(FALSE, nrow(counts_matrix))
rown <- rownames(counts_matrix)
chr <- do.call(rbind, str_split(rown, "_"))[,1]
bool_y <- chr == "X" | chr == "chrX" | chr == "ChrX"
bool_x <- chr == "Y" | chr == "chrY" | chr == "ChrY"
indexes_to_remove[bool_y | bool_x] <- TRUE
mydata_filtered <- counts_matrix[!indexes_to_remove,]
mydataNormalized <- t(t(mydata_filtered)/colSums(mydata_filtered, na.rm = TRUE))

pca <- prcomp(t(mydataNormalized), rank = 5)
fviz_eig(pca)
plot3d(pca$x[,c(1,2,3)])
save(pca, file=paste0(wd, "pca.rda"))
x <- pca$x
save(x, file=paste0(wd, "x.rda"))
```


```{r}
open3d()
rgl.bg(color = "grey") 
#plot3d(pca$x[,1:3], col=colors)
plot3d(x2[,1:3], col=colors)
if (!rgl.useNULL())
  play3d(spin3d(axis = c(1, 1, 1), rpm = 4), duration = 30, )
```


#Step 5
- Pseudo-automate clustering. 
This step looks at 30 different hierarchical clustering methods and chooses an "optimal" clustering assignment. You will probably want to fiddle with `n_clusters` to a number between 25-40. `USE_METRICS` attempts to use unsupervised clustering heuristics to choose the best clustering method. However, I've found the choosing the clustering method with the smallest, largest cluster size is usually best. For example, if clustering method A has clusters of size (1000, 900, 800, 700, 100) and method B had (750, 700, 700, 700, 650), method B is best. The results of this are stored in the `ct` object. heuristics approach is stored in `rval` object
```{r}
n_clusters <- 25 
USE_METRICS <- FALSE

wd <- ""
load(paste0(wd, "x.rda"))
load(paste0(wd, "pca.rda"))

set.seed(123)
pca_loadings <- x

hclust_methods <- c("ward.D", "ward.D2", "single", "complete", "average", "mcquitty", "median", "centroid") 
distance_methods <- c("euclidean", "maximum", "canberra", "minkowski")
mink_p <- c(10)
results <- expand.grid(hclust_methods, distance_methods)
colnames(results) <- c("agglomeration", "distance")
results$db <- 0
results$silhouette <- 0
results$dunn <- 0

dist_eucl <- dist(pca_loadings[,1:3], method="euclidean") 
dist_maxi <- dist(pca_loadings[,1:3], method="maximum") 
dist_canb <- dist(pca_loadings[,1:3], method="canberra") 
dist_mink <- dist(pca_loadings[,1:3], method="minkowski", p=100)

cuts <- vector("list", n_clusters)

USE_METRICS <- FALSE

for(i in 1:nrow(results)){
  print(i)
  dist_mat <- switch(results$distance[i] %>% as.character(), "euclidean"=dist_eucl, "maximum"=dist_maxi, "canberra"=dist_canb, "minkowski"=dist_mink)
  hclust <- hclust(dist_mat, method=results$agglomeration[i]) 
  cut_avg <- cutree(hclust, k=n_clusters)
  temp_names_srt <- names(srt(cut_avg))
  cuts[[i]] <- sapply(unname(cut_avg), function(x) which(x == temp_names_srt))
  
  if(USE_METRICS){
    results$db[i] <- index.DB(pca_loadings[,1:3], cut_avg, centrotypes="centroids", p=3)$DB
    results$silhouette[i] <- mean(silhouette(cut_avg, dist_mat)[,3])
    results$dunn[i] <- dunn(dist_mat, cut_avg)    
  }
}

if(USE_METRICS){
  results <- results[order(results$silhouette, decreasing = TRUE),]
  rval <- results
  rval$db <- order(results$db, decreasing = FALSE)
  rval$dunn <- order(results$dunn, decreasing = TRUE)
  rval$silhouette <- order(results$silhouette, decreasing = TRUE)
  rval$sum <- rval$db + rval$dunn + rval$silhouette
  rval <- rval[order(rval$sum),]
  write.table(rval , paste0(wd, "clustering_metrics", n_clusters, ".tsv"), sep="\t", quote = FALSE, col.names = TRUE, row.names = FALSE)
}

ct <- as.data.frame(do.call(rbind, lapply(cuts, table)))
ct <- ct[order(ct[,1]), ]
```

#Step 6
Plot the clustering output.
```{r}
n <- n_clusters
automated_choice <- rownames(ct)[1] %>% as.integer()
choice <- automated_choice # change this to a different number if you don't like the automaticly generated output
sorted_clusters <- cuts[[choice]]
cols <- rainbow(n)[sample(1:n, n)]
plot3d(x2[,1:3], col=cols[sorted_clusters])
```

merge the small clusters to their nearest neighbor
```{r}
set.seed(123)
threshold <- 200 # merge clusters smaller than this size
cluster_centers <- do.call(rbind, lapply(1:n_clusters, function(i){
  message(i)
  if(length(x[sorted_clusters==i, ]) == 7){
    return(x[sorted_clusters==i, ])    
  } else {
    colMeans(x[sorted_clusters==i, ])  
  }
}) ) %>% as.data.frame()

tab <- table(sorted_clusters)
which_clusters_to_relabel <- which(tab < threshold) %>% unname
clusters_to_relabel <- x[sorted_clusters %in% which_clusters_to_relabel, ]
bool_cluster_relabel <- sorted_clusters %in% which_clusters_to_relabel
main_cluster_centers <- cluster_centers[-c(which_clusters_to_relabel),]


nearest_clusters <- lapply(1:nrow(x), function(i){
  if(!bool_cluster_relabel[i]){ 
    return(sorted_clusters[i])
  } else {
    dists <- as.matrix(dist(rbind(x[i, ], main_cluster_centers)))[1, -1]
    return(as.numeric(names(dists)[which(dists==min(dists))][1])-1)
  }
}) %>% unlist %>% as.numeric()

l1 <- length(unique(nearest_clusters))
cols <- rainbow(l1)[sample(1:l1, l1)]
plot3d(x[,1:3], col=cols[nearest_clusters])


cohort_size <- 200
memb <- do.call(rbind, lapply(sort(unique(nearest_clusters)), function(i){
  if(length(which(sorted_clusters==i)) <= cohort_size){
    df <- data.frame(membership.sample_set_id=paste0("cluster_super_", i, "_COHORT"), 
                     samples = row.names(pca$x)[which(nearest_clusters==i)])
    return(df)
  } else {
    cohort_subset_indexes <- base::sample(which(sorted_clusters==i), cohort_size, replace = FALSE)
    nearest_points_in_cluster_indexes <- which(nearest_clusters==i)
    case_subset_indexes <- base::setdiff(nearest_points_in_cluster_indexes, cohort_subset_indexes)
    
    cohort_label <- paste0("cluster_super_", i, "_COHORT")
    case_label <- paste0("cluster_super_", i, "_CASE")
    
    cohort_samples <- row.names(pca$x)[cohort_subset_indexes]
    case_samples <- row.names(pca$x)[case_subset_indexes]
    
    df <- data.frame(membership.sample_set_id=c(
      rep(cohort_label, length(cohort_samples)), 
      rep(case_label, length(case_samples)) ), 
      samples=c(
        cohort_samples,
        case_samples),
      stringsAsFactors = FALSE)
    return(df)
  }
}) )
write.table(memb, paste0(wd, "membership_sfari.tsv"), sep="\t", col.names = TRUE, row.names = FALSE, quote=FALSE)
```

```{r}
cols <- wes_palette("Darjeeling1")
cols <- rainbow(n)[sample(1:n, n)]
open3d()
rgl.bg(color = "white") 
plot3d(x[,1:3], col=cols[nearest_clusters])
if (!rgl.useNULL())
  play3d(spin3d(axis = c(1, 1, 1), rpm = 4), duration = 30, )
```

# cluster on sex chromosome
currently, gCNV doesn't handle X and Y ploidy very well. The recomended approach is to sub cluster each super cluster from above into male and female sub clusters manually based on read depth at X/Y chromosomes
```{r}
files <- list.files(wd, pattern=".exons.counts.tsv", full.names = TRUE, recursive = TRUE)

cluster <- makeCluster(detectCores()-1)
clusterExport(cl=cluster, varlist=c("files", "str_replace_all"))
counts_dfs <- parLapply(cluster, files, function(x){
   cbind(read.table(x, sep="\t", header=TRUE, stringsAsFactors = FALSE, col.names = c("chr", "start", "end", "count"), comment.char = "@"),
        str_replace_all(basename(x), ".exons.counts.tsv", ""))
})
stopCluster(cluster)

names(counts_dfs) <- str_replace_all(basename(files), ".exons.counts.tsv", "")

total_counts <- lapply(counts_dfs, function(x){
  x <- x[!(x$start<=2781479 & x$end>=10001),] # remove PAR1
  x <- x[!((x$chr=="chrX" & x$start<=156030895 & x$end>=155701383) | 
           (x$chr=="chrY" & x$start<=57217415 & x$end>=56887903)),] # remove PAR2
  data.frame(xcount = sum(x$count[x$chr=="chrX"]), 
             ycount = sum(x$count[x$chr=="chrY"]), 
             sample = as.character(x[1,5]), stringsAsFactors = FALSE)
})

merged_counts <- do.call(rbind, total_counts)
merged_counts$x <- merged_counts$xcount / median(merged_counts$xcount)
merged_counts$y <- merged_counts$ycount / median(merged_counts$ycount)

memb <- read.table(paste0(wd, "membership_sfari.tsv"), sep="\t", header=TRUE, stringsAsFactors = FALSE)
memb <- memb[str_detect(memb$membership.sample_set_id, "cluster_super_.*[COHORT_CASE]"), ]

merged_counts$membership <- sapply(merged_counts$sample, function(x){
  unique(memb$membership.sample_set_id[grepl(x, memb$sample)])[1]
})
merged_counts$super_cluster <- merged_counts$membership %>% str_replace_all("_(COHORT|CASE)", "") %>% str_replace_all("_super", "")

ggplot(merged_counts, aes(x=x, y=y, color=super_cluster)) + 
  geom_point() + 
  xlab("normalized chrX counts") + 
  ylab("normalized chrY counts") + 
  ggtitle("normalized chrX and chrY counts, epi")
```

make sure to manually check each graph produced here to make sure clusters are well assigned
```{r}
set.seed(4)

n_super_clusters <- merged_counts$super_cluster %>% unique %>% length
super_clusters <- merged_counts$super_cluster %>% unique
merged_counts$sex_cluster <- "-1"
merged_counts$sex_cluster_sub <- "-1"

# TODO change to lapply?
for(i in 1:n_super_clusters){
  n_sub_cluster <- 2
  current_super_cluster <- merged_counts[merged_counts$super_cluster == super_clusters[i],]

  gclust <- GMM(current_super_cluster[, c("x", "y")], n_sub_cluster, km_iter = 10, em_iter=50)
  pr <- predict_GMM(current_super_cluster[, c("x", "y")], gclust$centroids, gclust$covariance_matrices, gclust$weights)
 # plot(current_super_cluster[, c("x", "y")], col=c("RED","BLUE")[pr$cluster_labels+1], pch=20, main=super_clusters[i])
  labels <- c("A", "B")[1 + pr$cluster_labels]
  sex_labels <- labels
  
  # this is quite bad rn, B, C denote quality
  x_mean_A <- mean(current_super_cluster$x[labels=="A"])
  x_mean_B <- mean(current_super_cluster$x[labels=="B"])
  y_mean_A <- mean(current_super_cluster$y[labels=="A"])
  y_mean_B <- mean(current_super_cluster$y[labels=="B"])
  if(x_mean_A < x_mean_B & y_mean_A > y_mean_B){
    sex_labels[sex_labels=="A"] <- "Y"
    sex_labels[sex_labels=="B"] <- "X"
  } else if(x_mean_A > x_mean_B & y_mean_A < y_mean_B) {
    sex_labels[sex_labels=="A"] <- "X"
    sex_labels[sex_labels=="B"] <- "Y"
  } else if(y_mean_A > y_mean_B){
    sex_labels[sex_labels=="A"] <- "YB"
    sex_labels[sex_labels=="B"] <- "XB"
  } else if(y_mean_A < y_mean_B) {
    sex_labels[sex_labels=="A"] <- "XB"
    sex_labels[sex_labels=="B"] <- "YB"
  } else if(x_mean_A < x_mean_B){
    sex_labels[sex_labels=="A"] <- "YC"
    sex_labels[sex_labels=="B"] <- "XC"
  } else if(x_mean_A > x_mean_B) {
    sex_labels[sex_labels=="A"] <- "XC"
    sex_labels[sex_labels=="B"] <- "YC"
  } 
  sub_labels <- sex_labels
  labels <- sub_labels
  current_super_cluster$sub_labels <- sex_labels
  print(
    ggplot(current_super_cluster, aes(x=x, y=y, color=sub_labels)) + 
    geom_point() + 
    xlab("normalized chrX counts") + 
    ylab("normalized chrY counts") + 
    ggtitle(super_clusters[i]) 
  )
  
  merged_counts$sex_cluster[merged_counts$super_cluster == super_clusters[i]] <- paste0(super_clusters[i], "_", labels) 
  
  for(k in unique(labels)){
    if(length(which(labels==k)) <= 200){
      sub_labels[which(labels==k)] <- paste0(sub_labels[which(labels==k)], "_COHORT")
    } else {
      cohort_subset_indexes <- base::sample(which(labels==k), 200, replace = FALSE)
      case_subset_indexes <- base::setdiff(which(labels==k), cohort_subset_indexes)
      
      sub_labels[cohort_subset_indexes] <- paste0(sub_labels[cohort_subset_indexes], "_COHORT")
      sub_labels[case_subset_indexes] <- paste0(sub_labels[case_subset_indexes], "_CASE")
      
    }
  }
  
  merged_counts$sex_cluster_sub[merged_counts$super_cluster == super_clusters[i]] <- paste0(super_clusters[i], "_", sub_labels) 
}
```

# if any of the clusters don't look good, redo the clustering below, editing the super_clusters_to_re_cluster character vecor
```{r}
set.seed(123)
super_clusters_to_re_cluster <- c("cluster_24", "cluster_12")

for(i in super_clusters_to_re_cluster){
  current_super_cluster <- merged_counts[merged_counts$super_cluster == i,]
  
  dclust <- dbscan(current_super_cluster[, c("x", "y")], eps=0.1, minPts = 10); table(dclust$cluster); lab <- dclust$cluster + 1
  n_clusters <- length(unique(lab))
  x <- current_super_cluster[, c("x", "y")]
  sorted_clusters <- sapply(unname(lab), function(x) which(x == names(srt(lab))))
  cluster_centers <- do.call(rbind, lapply(1:n_clusters, function(i){
    if(nrow(x[sorted_clusters==i, ]) == 1){
      return(x[sorted_clusters==i, ])    
    } else {
      colMeans(x[sorted_clusters==i, ])  
    }
  }) ) %>% as.data.frame()
  
  tab <- table(sorted_clusters)
  which_clusters_to_relabel <- sorted_clusters[!sorted_clusters %in% c(1,2)] %>% unique()
  bool_cluster_relabel <- sorted_clusters %in% which_clusters_to_relabel
  main_cluster_centers <- cluster_centers[-c(which_clusters_to_relabel),]
  
  nearest_clusters <- lapply(1:nrow(x), function(i){
    if(!bool_cluster_relabel[i]){ 
      return(sorted_clusters[i])
    } else {
      dists <- as.matrix(dist(rbind(x[i, ], main_cluster_centers)))[1, -1]
      return(as.numeric(names(dists)[which(dists==min(dists))][1]))
    }
  }) %>% unlist %>% as.numeric()
  
  labels <- c("A", "B")[nearest_clusters]
  sex_labels <- labels
  
  # this is quite bad rn, B, C denote quality
  x_mean_A <- mean(current_super_cluster$x[labels=="A"])
  x_mean_B <- mean(current_super_cluster$x[labels=="B"])
  y_mean_A <- mean(current_super_cluster$y[labels=="A"])
  y_mean_B <- mean(current_super_cluster$y[labels=="B"])
  if(x_mean_A < x_mean_B & y_mean_A > y_mean_B){
    sex_labels[sex_labels=="A"] <- "Y"
    sex_labels[sex_labels=="B"] <- "X"
  } else if(x_mean_A > x_mean_B & y_mean_A < y_mean_B) {
    sex_labels[sex_labels=="A"] <- "X"
    sex_labels[sex_labels=="B"] <- "Y"
  } else if(y_mean_A > y_mean_B){
    sex_labels[sex_labels=="A"] <- "YB"
    sex_labels[sex_labels=="B"] <- "XB"
  } else if(y_mean_A < y_mean_B) {
    sex_labels[sex_labels=="A"] <- "XB"
    sex_labels[sex_labels=="B"] <- "YB"
  } else if(x_mean_A < x_mean_B){
    sex_labels[sex_labels=="A"] <- "YC"
    sex_labels[sex_labels=="B"] <- "XC"
  } else if(x_mean_A > x_mean_B) {
    sex_labels[sex_labels=="A"] <- "XC"
    sex_labels[sex_labels=="B"] <- "YC"
  } 
  sub_labels <- sex_labels
  labels <- sub_labels
  current_super_cluster$sub_labels <- sex_labels
  print(ggplot(current_super_cluster, aes(x=x, y=y, color=sub_labels)) + 
  geom_point() + 
  xlab("normalized chrX counts") + 
  ylab("normalized chrY counts") + 
  ggtitle(i) )
  
  merged_counts$sex_cluster[merged_counts$super_cluster == i] <- paste0(i, "_", labels) 
  
  for(k in unique(labels)){
    if(length(which(labels==k)) <= 200){
      sub_labels[which(labels==k)] <- paste0(sub_labels[which(labels==k)], "_COHORT")
    } else {
      cohort_subset_indexes <- base::sample(which(labels==k), 200, replace = FALSE)
      case_subset_indexes <- base::setdiff(which(labels==k), cohort_subset_indexes)
      
      sub_labels[cohort_subset_indexes] <- paste0(sub_labels[cohort_subset_indexes], "_COHORT")
      sub_labels[case_subset_indexes] <- paste0(sub_labels[case_subset_indexes], "_CASE")
      
    }
  }
  merged_counts$sex_cluster_sub[merged_counts$super_cluster == i] <- paste0(i, "_", sub_labels) 
}
```


# write table
```{r}
for(i in 1:n_super_clusters){
  current_super_cluster <- merged_counts[merged_counts$super_cluster == super_clusters[i],]
  print(ggplot(current_super_cluster, aes(x=x, y=y, color=sex_cluster)) + 
  geom_point() + 
  xlab("normalized chrX counts") + 
  ylab("normalized chrY counts") + 
  ggtitle(super_clusters[i]) )
}
memb <- data.frame(membership.sample_set_id=merged_counts$sex_cluster_sub, sample=merged_counts$sample)
table(memb$membership.sample_set_id)
write.table(memb, paste0(wd, "membership_plus_sex_cluster.tsv"), sep="\t", col.names = TRUE, row.names = FALSE, quote=FALSE)
```


update sample file and upload to terra
```{r}
wd <- ""
sample <- read.table(paste0(wd, "sample.tsv"), sep="\t", header=TRUE, stringsAsFactors = FALSE, na.strings = "weoifjoewif")
sample$exons <- NULL
ent <- read.table(paste0(wd, "sample_set_entity.tsv"), sep="\t", header=TRUE, stringsAsFactors = FALSE, na.strings = "weoifweoif")
  
samples <- ent$sample_all %>% str_replace_all("\\[|\\]|\"", "") %>% str_split(",") %>% unlist %>% unique
exons <- ent$counts_exons_all %>% str_replace_all("\\[|\\]|\"", "") %>% str_split(",") %>% unlist %>% unique

samples <- samples[samples!=""]
exons <- exons[exons!=""]

temp1 <- sapply(1:length(exons), function(x) { grepl(samples[x], exons[x])}) %>% table # all good

sample$exons[sample$entity.sample_id %in% samples] <- sapply(sample$entity.sample_id[sample$entity.sample_id %in% samples], function(x) {
  exons[samples==x]
})

temp1 <- lapply(sample$entity.sample_id[sample$entity.sample_id %in% samples], function(x) {
  exons[samples==x]
})
temp2 <- sapply(temp1, length)

temp_samp <- sample$entity.sample_id[sample$entity.sample_id %in% samples]
temp_exon <- sample$exons[sample$entity.sample_id %in% samples]
temp2 <- sapply(1:length(temp_samp), function(x) { grepl(temp_samp[x], temp_exon[x])}) %>% table # all good


write.table(sample, paste0(wd, "sample_corrections.tsv"), sep="\t", col.names = TRUE, row.names = FALSE, quote=FALSE)
```

```{r}
wd <- "C:/Users/iwong/Documents/MGH/epi/post_collectCoverage/"
df <- read.table(paste0(wd, "sample_plus_new_exons.tsv"), sep="\t", header=TRUE, stringsAsFactors = FALSE, na.strings = "woiefowiejfoiwejf")
```




#Step 11
After running cohort mode, you will need to upload certain reference files so that case mode can use the model built by cohort mode
```{r}
wd <- ""
meta <- read.table(paste0(wd, "sample_set_entity.tsv"), sep="\t", header=TRUE, stringsAsFactors = FALSE)
cohorts <- meta[,1][grepl("COHORT", meta[,1])]  # change to your cohort
pse_case <- NULL
gbucket = 'gs://fc-..../000_aux/' # change to your gbucket
for(i in 1:length(cohorts)){
    cohort <- cohorts[i]
    ind <- which(meta[,1] == cohort)
    case <- str_replace(cohort, "COHORT", "CASE")
    if(case %in% meta[,1]){
     if(TRUE){
        message(case)
        makeFiles("calling_configs", case, meta[ind,], gbucket)
        makeFiles("denoising_configs", case, meta[ind,], gbucket)
        makeFiles("gcnvkernel_version", case, meta[ind,], gbucket)
        makeFiles("gcnv_model_tars", case, meta[ind,], gbucket)
        makeFiles("sharded_interval_lists", case, meta[ind,], gbucket)    
        pse_case <- rbind(pse_case, meta[ind,])
    }}
}

makeFiles <- function(name, cohort, mat, gbucket){
    output_name <- paste0(cohort, "-", name, ".txt")
    colind <- which(colnames(mat)==name)
    tmp <- mat[,colind]
    tmp <- str_replace_all(tmp, '\"', "")
    files <- unlist(str_split(str_replace_all(tmp, "(\\[)|]", ""), ","))
    write.table(files, quote=FALSE, sep="\t", col.names=F, row.names=F, file=paste0("~/downloads/", output_name))
    system2("gsutil", paste0("cp ~/downloads/", output_name, " ", gbucket, output_name))
    #file.remove(paste0("~/downloads/", output_name))
}

## Update the PARTICIPANT SET file
pse_case <- pse_case[, which(colnames(pse_case) %in% c("entity.sample_set_id", "intervals", "filtered_intervals", "contig_ploidy_model_tar"))]
    pse_case[,1] <- str_replace(pse_case[,1], "COHORT", "CASE")    
    pse_case$file_gcnv_model_tars <- paste0(gbucket, pse_case[,1], "-gcnv_model_tars.txt")
    pse_case$file_calling_configs <- paste0(gbucket, pse_case[,1], "-calling_configs.txt")
    pse_case$file_denoising_configs <- paste0(gbucket, pse_case[,1], "-denoising_configs.txt")
    pse_case$file_gcnvkernel_version <- paste0(gbucket, pse_case[,1], "-gcnvkernel_version.txt")
    pse_case$file_sharded_interval_lists <- paste0(gbucket, pse_case[,1], "-sharded_interval_lists.txt")        
        pse_case <- rbind(as.character(colnames(pse_case)), apply(pse_case, 2, as.character))
        pse_case[1,1] <- "entity:sample_set_id"
        write.table(pse_case, sep="\t", row.names=F, col.names=F, file=paste0(wd, "/c_pse.txt"), quote=F)
```



#Step 12
on Terra/Fireloud, run gCNV. 

#Step 13

Download the segment VCFs and unzip them. 
```{r}
wd <- "/path/to/folder/"
system2("java", sprintf("-Xmx16G -jar %s downloadSegmentsVCFs %ssample_set_entity.tsv %s genotyped_segments_vcf", jar_path, wd, wd ))
```

#Step 14
Convert VCFs to BED format
```{r}
system2("java", sprintf("-Xmx16G -jar %s convertVCFsToBEDFormat %sgcnv_vcftobed.bed genotyped-segments- .vcf", jar_path, wd, wd ))
```


#Step 15
Cluster calls together. 
```{r}
system2("java", sprintf("-Xmx16G -jar %s bedcluster %sgcnv_vcftobed.bed %sgcnv_bedclusterd.bed", jar_path, wd, wd))
```

#Step 16
defragment calls
```{r}
system2("java", sprintf("-Xmx16G -jar %s defragment %sgcnv_bedclusterd.bed %sgcnv_defragmented.bed", jar_path, wd, wd))
```

#Step 17
calculate variant frequency
```{r}
system2("java", sprintf("-Xmx16G -jar %s calculateFrequency %sgcnv_defragmented.bed variant_name %sgcnv_frequency.bed", jar_path, wd, wd))
```

#Step 18
apply filters
```{r}
system2("java", sprintf("-Xmx16G -jar %s filter %sgcnv_frequency.bed %gcnv_filtered.bed", jar_path, wd, wd))
```

#Step 19
annotate with genes
```{r}
gencode_gtf <- "/path/to/gencode/gtf/file"
system2("java", sprintf("-Xmx16G -jar %s annotateWithGenes any %s %gcnv_filtered.bed %gcnv_temp1.bed svtype", jar_path, gencode_gtf, wd, wd))
system2("java", sprintf("-Xmx16G -jar %s countExons %gcnv_temp1.bed genes_any_overlap %s %sgcnv_temp2.bed", jar_path, wd, gencode_gtf, wd))
system2("java", sprintf("-Xmx16G -jar %s annotateWithGenes strict %s %sgcnv_temp2.bed %sgcnv_temp3.bed svtype", jar_path, gencode_gtf, wd, wd))
system2("java", sprintf("-Xmx16G -jar %s countExons %gcnv_temp3.bed genes_strict_overlap %s %sgcnv_annotated.bed", jar_path, wd, gencode_gtf, wd))
```

alternatively, use this:

```{}
#!/bin/bash
name=""
gtf="/mgh/references/gencode.v34.annotation.gtf"
java -jar /mgh/scripts/gCNV_helper.jar convertVCFsToBEDFormat ./ ${name}_vcftobed.bed genotyped-segments- .vcf
java -jar /mgh/scripts/gCNV_helper.jar bedcluster ${name}_vcftobed.bed  ${name}_bedclustered.bed 
java -jar /mgh/scripts/gCNV_helper.jar defragment ${name}_bedclustered.bed ${name}_defragmented.bed
java -jar /mgh/scripts/gCNV_helper.jar calculateFrequency ${name}_defragmented.bed variant_name ${name}_frequencied.bed
java -jar /mgh/scripts/gCNV_helper.jar filter ${name}_frequencied.bed ${name}_filtered.bed
java -jar /mgh/scripts/gCNV_helper.jar annotateWithGenes any ${gtf} ${name}_filtered.bed ${name}_intermediate1.bed svtype
java -jar /mgh/scripts/gCNV_helper.jar countExons ${name}_intermediate1.bed genes_any_overlap ${gtf} ${name}_intermediate2.bed
java -jar /mgh/scripts/gCNV_helper.jar annotateWithGenes strict ${gtf} ${name}_intermediate2.bed ${name}_intermediate3.bed svtype
java -jar /mgh/scripts/gCNV_helper.jar countExons ${name}_intermediate3.bed genes_strict_overlap ${gtf} ${name}_annotated.bed
```


`gcnv_annotated.bed` is the main output file. You can use other gCNV_helper methods to produce other metadata files or add metadata columns to this file at your own discretion


look at aneuploidies. First need to download the ploidy information
sh script to download ploidy calls, input is manifest file
```{}
#!/bin/bash

wcl=$(wc -l ${1} | cut -d " " -f1)
echo $wcl


for i in $(seq 1 ${wcl})
do
        file=$(sed ''${i}'!d' ${1})
        echo ${file}
        mkdir "ploidy_file_${i}"
        gsutil cp ${file} "./ploidy_file_${i}/ploidy_file_${i}.tar.gz"
done

for d in $(ls -d ploidy*/)
do
echo $d
cd $d
tar -xf *tar.gz
cd ..
done
```

Get ploidy conunts
```{r}
wd <- ""
ploidy_files <- list.files(paste0(wd ,"ploidy/"), pattern="contig_ploidy.tsv", recursive = TRUE, full.names = TRUE)

ploidy_dfs <- lapply(ploidy_files, function(x){
  df <- read.table(x, comment.char = "@", header=TRUE, stringsAsFactors=FALSE, quote="", fill=TRUE)
  df$sample <- str_extract_all(scan(x, what="character", sep="\n", nlines=1, quiet=TRUE)[[1]], "(?<=SM:).*")[[1]]
  return(df)
})

ploidy_df <- do.call(rbind, ploidy_dfs)
sex_ploidy_sums <- do.call(c, lapply(ploidy_dfs, function(df) sum(df$PLOIDY[str_detect(df$CONTIG, "X|Y")])))
sex_ploidy_samples <- unique(do.call(rbind, ploidy_dfs[which(sex_ploidy_sums!=2)])$sample)
autosome_ploidy_samples <- ploidy_df[ploidy_df$PLOIDY!=2 & !str_detect(ploidy_df$CONTIG, "X|Y"),]$sample
ploidy_samples <- c(sex_ploidy_samples, autosome_ploidy_samples)
```

Download DCR files
```{r}
# This will take a while, you might want to subset to files with aneuploidies
system2("java", sprintf("-Xmx16G -jar %s getBarcodeCounts %ssample_set_entity.tsv %s/ploidy/ denoised_copy_ratios", jar_path, wd, wd ))
system2("gunzip", sprintf("%s/*/*.tar.gz")) # make sure output are each uncompressed
```


Plot ploidy counts,
```{r}
wd <- ""
dcr_files <- list.files(wd, pattern="denoised_copy_ratios-", recursive = TRUE, full.names = TRUE)
temp1 <- str_detect(dcr_files, paste0("(",paste(ploidy_samples, collapse=")|(") , ")")) 
temp2 <- dcr_files[temp1]

cluster <- makeCluster(detectCores()-1)
clusterExport(cl=cluster, varlist=c("temp2", "str_detect", "str_extract"))
dcr_dfs <- parLapply(cluster, temp2, function(x){
  lines <- scan(x, what="character", sep="\n", quiet=TRUE)
  df <- read.table(textConnection(lines), comment.char = "@", header=TRUE, stringsAsFactors=FALSE, quote="", fill=TRUE)
  df$sample <- str_extract(lines[str_detect(lines, "SM:")], "(?<=SM:).*")[[1]]
  return(df)
})
stopCluster(cluster)
dcr_df <- do.call(rbind, dcr_dfs)

#plot linear copy ratio over chromosome for autosomes
autosome_ploidy_dfs <- ploidy_df[ploidy_df$PLOIDY!=2 & (ploidy_df$sample %in% autosome_ploidy_samples) & !str_detect(ploidy_df$CONTIG, "X|Y"), ]
for(i in 1:nrow(autosome_ploidy_dfs)){
  df <- dcr_df[dcr_df$sample==autosome_ploidy_dfs$sample[i] & dcr_df$CONTIG==autosome_ploidy_dfs$CONTIG[i], ]
  print(plot_ploidy(df))
  pdf(sprintf("%sploidy_sample_%s_%s.pdf", wd, df$sample[1], df$CONTIG[1]))
  my_plot <- plot_ploidy(df)
  print(my_plot)
  dev.off()
}

sex_ploidy_dfs <- ploidy_df[(ploidy_df$sample %in% sex_ploidy_samples) & str_detect(ploidy_df$CONTIG, "X|Y"), ]
df_instances <- rep("-1", unique(sex_ploidy_dfs$sample) %>% length)
for(i in seq_along(unique(sex_ploidy_dfs$sample))){
  par(mfrow=c(1,2))
  df <- dcr_df[dcr_df$sample==unique(sex_ploidy_dfs$sample)[i], ]
  plot_x <- plot_ploidy(df[str_detect(df$CONTIG, "X"),])
  plot_y <- plot_ploidy(df[str_detect(df$CONTIG, "Y"),])
  grid.arrange(plot_x, plot_y, ncol=2)
  
  temp_df_x <- df[str_detect(df$CONTIG, "X"),]
  temp_df_y <- df[str_detect(df$CONTIG, "Y"),]
  df_instances[i] <- c(
                          rep(temp_df_x$CONTIG[1], ploidy_df[ploidy_df$CONTIG==temp_df_x$CONTIG[1] & ploidy_df$sample==temp_df_x$sample[1],]$PLOIDY[1]),
                          rep(temp_df_y$CONTIG[1], ploidy_df[ploidy_df$CONTIG==temp_df_y$CONTIG[1] & ploidy_df$sample==temp_df_y$sample[1],]$PLOIDY[1])
                          ) %>% paste0(collapse = "")

  my_plot <- arrangeGrob(plot_x, plot_y, ncol=2)
  ggsave(sprintf("%s/dcr_plots/ploidy_sample_%s_sex_chroms.pdf", wd, df$sample[1]), my_plot)
}
```




Main Figures
variant count boxplots
```{r}
wd <- ""
gcnv <- read(wd, "gcn.bed")
# ploidy_samples <- read.table("ploidy_samples.txt", sep="\t", header=TRUE, stringsAsFactors = FALSE)[,1]
# ploidy_samples <- c()

qs_window <- seq(0, 100, 10)
total_variants <- rep(0, length(qs_window))
variant_counts <- vector("list", length(qs_window))

for(i in seq_along(qs_window)){
  filtered_qs <- gcnv$QS >= qs_window[i]
  filtered_vafs <- gcnv$vaf <= 0.01
  filtered <- gcnv[filtered_qs & filtered_vafs ,]
  total_variants[i] <- length(unique(filtered$name))
  variant_counts[[i]] <- as.numeric(table(filtered$sample))
}

n_outliers <- lapply(variant_counts, function(x) length(boxplot(x, plot=FALSE)$out) )

lengths <- sapply(variant_counts, length)
labels <- lapply(seq_along(qs_window), function(x){rep(qs_window[x], lengths[x])}) %>% unlist %>% as.character()

temp1 <- letters[seq_along(qs_window)]
labels2 <- lapply(seq_along(temp1), function(x){rep(temp1[x], lengths[x])}) %>% unlist
df <- data.frame(qs_threshold=labels, n_variants=unlist(variant_counts), class=labels2)
df$qs_threshold <- factor(df$qs_threshold, levels=qs_window)

df$n_variants_log2 <- (df$n_variants) %>% log2
df$n_variants_log10 <- df$n_variants %>% log10

gcnvhq <- gcnv[gcnv$HIGH_QUALITY, ]
write.table(gcnvhq, paste0(wd, "gcnv_HQ.tsv"), sep="\t", row.names = FALSE, col.names = TRUE, quote=FALSE)
```


```{r}
g1 <- ggplot(df, aes(x=qs_threshold, y=n_variants)) +
  geom_boxplot(outlier.size = NA, outlier.shape = NA, color=wes_palette("Zissou1")[1], fill=wes_palette("Zissou1")[2], alpha=0.6) + 
  coord_cartesian(ylim = c(0, 40)) +
  xlab("QS threshold") + 
  ylab("# of Variants per sample") +
  ggtitle("Variants per sample, outliers not shown") +
  theme(plot.title = element_text(hjust = 0.5))
g1
```


```{r}
g2 <- ggplot(df[df$qs_threshold!=0 & df$qs_threshold!=10,], aes(x=qs_threshold, y=n_variants)) +
  geom_boxplot(outlier.size = NA, outlier.shape = NA, color=wes_palette("Zissou1")[1], fill=wes_palette("Zissou1")[2], alpha=0.6) + 
  coord_cartesian(ylim = c(0, 16)) +
  xlab("QS threshold") + 
  ylab("# of Variants per sample") +
  ggtitle("Variants per sample, outliers not shown") +
  theme(plot.title = element_text(hjust = 0.5))
g2
```

variant count histograms
```{r}
g3 <- ggplot(df[df$qs_threshold==0,] , aes(x=n_variants_log2)) +
  geom_histogram(aes(y=..density..), colour="BLACK", fill=wes_palette("FantasticFox1")[1]) + 
  geom_density(alpha=.2, bw=0.3, size=1, color=wes_palette("FantasticFox1")[5]) +
  ylab("frequency") + 
  xlab("number of variants") +
  ggtitle(bquote(~log[2]~"transformed number of variants; QS threshold=0 ")) +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_x_continuous(breaks=0:10, labels=2^(0:10))
g3
```

```{r}
bks <- seq(0, 10, 0.6)
g4 <- ggplot(df[df$qs_threshold==50,] , aes(x=n_variants_log2)) +
  geom_histogram(aes(y=..density..), colour="BLACK", fill=wes_palette("FantasticFox1")[1], breaks=bks) + 
  geom_density(alpha=.2, bw=0.5, size=1, color=wes_palette("FantasticFox1")[5]) +
  ylab("frequency") + 
  xlab("number of variants") +
  ggtitle(bquote(~log[2]~"transformed number of variants; QS threshold=50 ")) +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_x_continuous(breaks=0:10, labels=2^(0:10))
g4
```


```{r}
bks <- seq(0, 10, 0.6)
g5 <- ggplot(df[df$qs_threshold==100,] , aes(x=n_variants_log2)) +
  geom_histogram(aes(y=..density..), colour="BLACK", fill=wes_palette("FantasticFox1")[1], breaks=bks) + 
  geom_density(alpha=.2, bw=0.9, size=1, color=wes_palette("FantasticFox1")[5]) +
  ylab("frequency") + 
  xlab("number of variants") +
  ggtitle(bquote(~log[2]~"transformed number of variants; QS threshold=100 ")) +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_x_continuous(breaks=0:10, labels=2^(0:10))
g5
```

overlapping histogram of size
```{r}
df <- gcnv[, c("start", "end", "svtype", "PASS_FREQ", "PASS_SAMPLE", "PASS_QS")]
df$size <- (df$end - df$start)/1000
df$size_log10 <- df$size %>% log10
df$size_log2 <- df$size %>% log2
df$HQ <- df$PASS_FREQ & df$PASS_QS & df$PASS_SAMPLE
```

```{r}
g8 <- ggplot(data=df[df$size>0.125 & df$size<1500, ], aes(x=size_log2, fill=svtype)) +
  geom_histogram(alpha=0.7, position = "identity", aes(y = ..density..)) +
  scale_fill_manual(values=c(wes_palette("FantasticFox1")[5], wes_palette("FantasticFox1")[3])) +
  scale_x_continuous(breaks=-4:10, labels = 2^(-4:10)) + 
  xlab("CNV size (KB)") + 
  ggtitle("Raw CNV size distribution") 
g8
```

```{r}
g9 <- ggplot(data=df[df$size>0.125 & df$size<1500 & df$HQ, ], aes(x=size_log2, fill=svtype)) +
  geom_histogram(alpha=0.7, position = "identity", aes(y = ..density..)) +
  scale_fill_manual(values=c(wes_palette("FantasticFox1")[5], wes_palette("FantasticFox1")[3])) +
  scale_x_continuous(breaks=-4:10, labels = 2^(-4:10)) + 
  xlab("CNV size (KB)") + 
  ggtitle("HQ CNV size distribution")
g9
```

venn diagram
```{r}
samp <- c(TRUE, FALSE)
freq <- c(TRUE, FALSE)
qs <- c(TRUE, FALSE)
temp_df <- expand.grid(samp, freq, qs)
colnames(temp_df) <- c("samp", "freq","qs")
temp_df$count <- -1
temp_df$percent_of_all_calls <- -1
temp_df$per_sample <- -1
for(i in 1:nrow(temp_df)){
  temp_df$count[i] <- nrow(gcnv[gcnv$PASS_SAMPLE==temp_df$samp[i] & gcnv$PASS_FREQ==temp_df$freq[i] & gcnv$PASS_QS==temp_df$qs[i],])
  temp_df$percent_of_all_calls[i] <- temp_df$count[i] / nrow(gcnv) * 100
  temp_df$per_sample[i] <- temp_df$count[i] / (gcnv$sample %>% unique %>% length)
}

length(unique(gcnv[gcnv$PASS_sample==temp_df$samp[i] & gcnv$PASS_freq==temp_df$freq[i] & gcnv$PASS_QS==temp_df$qs[i],]$sample))
dim(gcnv[gcnv$PASS_sample==temp_df$samp[i] & gcnv$PASS_freq==temp_df$freq[i] & gcnv$PASS_QS==temp_df$qs[i],])
length(unique(gcnv[gcnv$PASS_sample==temp_df$samp[i] & gcnv$PASS_freq==temp_df$freq[i] & gcnv$PASS_QS==temp_df$qs[i],]$name))

length(unique(gcnv$sample))
dim(gcnv)
length(unique(gcnv$name))

temp_df

pass_qs <- paste0(gcnv$sample[gcnv$PASS_QS], gcnv$name[gcnv$PASS_QS])
pass_freq <- paste0(gcnv$sample[gcnv$PASS_FREQ], gcnv$name[gcnv$PASS_FREQ])
pass_samp <- paste0(gcnv$sample[gcnv$PASS_SAMPLE], gcnv$name[gcnv$PASS_SAMPLE])

pass_qs %>% length()
pass_freq %>% length()
pass_samp %>% length()

library(RColorBrewer)
myCol <- brewer.pal(3, "Pastel2")
myCol <- wes_palette("Darjeeling1")[1:3]
library(VennDiagram)
venn.diagram(
  x = list(pass_qs, pass_freq, pass_samp),
  category.names = c("pass_qs" , "pass_freq" , "pass_sample"),
  filename = paste0(wd, 'venn_diagramm.png'),
  output=TRUE,
  print.mode = c("raw", "percent"),
  
  # Output features
  imagetype="png" ,
  height = 900 , 
  width = 900 , 
  resolution = 300,
  compression = "lzw",
  
  # Circles
  lwd = 2,
  lty = 'blank',
  fill = myCol,
  
  # Numbers
  cex = .6,
  fontface = "bold",
  fontfamily = "sans",
  
  # Set names
  cat.cex = 0.6,
  cat.fontface = "bold",
  cat.default.pos = "outer",
  cat.pos = c(-27, 27, 135),
  cat.dist = c(0.055, 0.055, 0.085),
  cat.fontfamily = "sans",
  rotation = 1
)
```
