---
title: "gCNV pre and post processing"
output: html_document
author: Isaac Wong
version: 2.25
---

https://github.com/theisaacwong/talkowski/tree/master/gCNV

To begin, load the required packages and some functions from my github
```{r}
source("my_libraries.R")
```


#Step 1
```{r}
wd <- "/path/to/folder/"
jar_path <- "/path/to/jar"
system2("java", sprintf("-Xmx16G -jar %s --help", jar_path)) # you might need to change -Xmx to how much memory you have available on your device
```



#Step 2
Run GATK CollectReadCounts on your samples. WDL link is below
https://github.com/theisaacwong/talkowski/tree/master/gCNV/WDL
Download the barcode counts files to the wd. If the column name in your manifest file isn't "counts_barcode" then change code. This chunk just makes a system call to run the jar, which itself makes a system call to gsutil to download the files. It's turtles all the way down. 
```{r}
wd <- "/path/to/folder/"
system2("java", sprintf("-Xmx16G -jar %s getBarcodeCounts %ssample_set_entity.tsv %s counts_barcode", jar_path, wd, wd ))
```

#Step 3
Convert the barcode count files into a matrix file where rows are samples and columns are intervals
```{r}
wd <- "/path/to/folder/"
system2("java", sprintf("-Xmx16G -jar %s getCountsMatrix %s %scounts_matrix.tsv .barcode.counts.tsv", jar_path, wd, wd ))
```

#Step 4
- perform data normalization
- remove x and y chromosomes
- perform PCA
- save the R PCA object
a scree plot for the PCA loadings is generated to help visualize the data. 
```{r}
wd <- "C:/Users/iwong/Documents/MGH/gCNV/testing/"
counts_matrix_file_name <- "test_matrix_10k.tsv"
pca <- getCountsPCA(paste0(wd, counts_matrix_file_name)) 
save(pca, file=paste0(wd, "PCA_loadings.rda"))
```

# Step 5 
- create clusters 
```{r}
load(paste0(wd, "PCA_loadings.rda"))
n_clusters <- 10 # 30 is optimal for a cohort size of ~20,000 samples
cluster_results <- clusterPrimaryClusters(pca$x, n_clusters=n_clusters, wd = wd)
print(cluster_results$cluster_counts)
```

#Step 6
Plot the clustering output. Change the 'choice' variable from 1 to 24 to cycle through the different clustering methods. (lower is "better")
```{r}
choice <- 3
sorted_clusters <- cluster_results$cluster_labels[, row.names(cluster_results$cluster_counts)[choice] %>% as.integer()]
cols <- rainbow(n_clusters)[sample(1:n_clusters, n_clusters)]
plot3d(pca$x[,1:3], col=cols[sorted_clusters])
```


merge the small clusters to their nearest neighbor
```{r}
membership <- relabelSmallClusters(pca = pca, n_clusters = n_clusters, sorted_clusters = sorted_clusters)
write.table(membership$membership_file, paste0(wd, "membership_file.tsv"), sep="\t", col.names = TRUE, row.names = FALSE, quote=FALSE)
```

```{r}
cols <- rainbow(n_clusters)[sample(1:n_clusters, n_clusters)]
open3d()
rgl.bg(color = "grey") 
plot3d(pca$x[,1:3], col=cols[membership$merged_clusters])
if (!rgl.useNULL())
  play3d(spin3d(axis = c(1, -1, 1), rpm = 4), duration = 60, )
```

# cluster on sex chromosome
make sure generated plots look good before continueing to next step
```{r}
membership_sex <- clusterOnSex(wd = "/directory/of/counts/files/", membership_file = "/path/to/write/membership_file/")
write.table(membership_sex, "/path/to/write/sex_membership_file/", sep="\t", col.names = TRUE, row.names = FALSE, quote=FALSE)
```


update sample file and upload all three files, this requires some ad hoc file massaging and you will probbaly need to adjust this template to suit your files
```{r}
wd <- ""
sample <- read.table(paste0(wd, "sample.tsv"), sep="\t", header=TRUE, stringsAsFactors = FALSE, na.strings = "weoifjoewif", check.names = FALSE)
sample$exons <- NULL
ent <- read.table(paste0(wd, "sample_set_entity.tsv"), sep="\t", header=TRUE, stringsAsFactors = FALSE, na.strings = "weoifweoif", check.names = FALSE)
  
samples <- ent$sample %>% str_replace_all("\\[|\\]|\"", "") %>% str_split(",") %>% unlist %>% unique
exons <- ent$counts_exons_full %>% str_replace_all("\\[|\\]|\"", "") %>% str_split(",") %>% unlist %>% unique

samples <- samples[samples!=""]
exons <- exons[exons!=""]

temp1 <- sapply(1:length(exons), function(x) { grepl(samples[x], exons[x])}) %>% table # all good

sample$exons[sample$`entity:sample_id` %in% samples] <- sapply(sample$`entity:sample_id`[sample$`entity:sample_id` %in% samples], function(x) {
  exons[samples==x]
})

temp1 <- lapply(sample$`entity:sample_id`[sample$`entity:sample_id` %in% samples], function(x) {
  exons[samples==x]
})
temp2 <- sapply(temp1, length)

temp_samp <- sample$`entity:sample_id`[sample$`entity:sample_id` %in% samples]
temp_exon <- sample$exons[sample$`entity:sample_id` %in% samples]
temp2 <- sapply(1:length(temp_samp), function(x) { grepl(temp_samp[x], temp_exon[x])}) %>% table # all good

write.table(sample, paste0(wd, "sample_with_exons.tsv"), sep="\t", col.names = TRUE, row.names = FALSE, quote=FALSE)
```




https://portal.firecloud.org/?return=firecloud#methods/vruano-broad/GATK-gCNV-Cohort-Mode/7
https://github.com/broadinstitute/gatk/tree/master/scripts/cnv_wdl/germline



#Step 11
After running cohort mode, you will need to upload certain reference files so that case mode can use the model built by cohort mode
```{r}
makeFiles <- function(name, cohort, mat, gbucket){
    output_name <- paste0(cohort, "-", name, ".txt")
    colind <- which(colnames(mat)==name)
    tmp <- mat[,colind]
    tmp <- str_replace_all(tmp, '\"', "")
    files <- unlist(str_split(str_replace_all(tmp, "(\\[)|]", ""), ","))
    write.table(files, quote=FALSE, sep="\t", col.names=F, row.names=F, file=paste0(wd, output_name))
    system2("gsutil", paste0("cp ", wd, output_name, " ", gbucket, output_name))
    #file.remove(paste0("~/downloads/", output_name))
}

wd <- "C:/Users/iwong/MGH/"
meta <- read.table(paste0(wd, "sample_set_entity.tsv"), sep="\t", header=TRUE, stringsAsFactors = FALSE)
cohorts <- meta[,1][grepl("COHORT", meta[,1])]  # change to your cohort
pse_case <- NULL
gbucket = 'gs://fc-.../000-models' # change to your gbucket
for(i in 1:length(cohorts)){
    cohort <- cohorts[i]
    ind <- which(meta[,1] == cohort)
    case <- str_replace(cohort, "COHORT", "CASE")
    #if(case %in% meta[,1]){
     if(TRUE){
        message(case)
        makeFiles("calling_configs", case, meta[ind,], gbucket)
        makeFiles("denoising_configs", case, meta[ind,], gbucket)
        makeFiles("gcnvkernel_version", case, meta[ind,], gbucket)
        makeFiles("gcnv_model_tars", case, meta[ind,], gbucket)
        makeFiles("sharded_interval_lists", case, meta[ind,], gbucket)    
        pse_case <- rbind(pse_case, meta[ind,])
    }
}



## Update the PARTICIPANT SET file
pse_case <- pse_case[, which(colnames(pse_case) %in% c("entity.sample_set_id", "intervals", "filtered_intervals", "contig_ploidy_model_tar"))]
    pse_case[,1] <- str_replace(pse_case[,1], "COHORT", "CASE")    
    pse_case$file_gcnv_model_tars <- paste0(gbucket, pse_case[,1], "-gcnv_model_tars.txt")
    pse_case$file_calling_configs <- paste0(gbucket, pse_case[,1], "-calling_configs.txt")
    pse_case$file_denoising_configs <- paste0(gbucket, pse_case[,1], "-denoising_configs.txt")
    pse_case$file_gcnvkernel_version <- paste0(gbucket, pse_case[,1], "-gcnvkernel_version.txt")
    pse_case$file_sharded_interval_lists <- paste0(gbucket, pse_case[,1], "-sharded_interval_lists.txt")        
        pse_case <- rbind(as.character(colnames(pse_case)), apply(pse_case, 2, as.character))
        pse_case[1,1] <- "entity:sample_set_id"
        write.table(pse_case, sep="\t", row.names=F, col.names=F, file=paste0(wd, "./c_pse.txt"), quote=F)
```


# run this as an sh script
```{sh}
#!/bin/bash
name=""
gtf="/mgh/references/gencode.v34.annotation.gtf"
java -jar /mgh/scripts/gCNV_helper.jar convertVCFsToBEDFormat ./ ${name}_vcftobed.bed genotyped-segments- .vcf
java -jar /mgh/scripts/gCNV_helper.jar bedcluster ${name}_vcftobed.bed  ${name}_bedclustered.bed
java -jar /mgh/scripts/gCNV_helper.jar defragment ${name}_bedclustered.bed ${name}_defragmented.bed
java -jar /mgh/scripts/gCNV_helper.jar calculateFrequency ${name}_defragmented.bed variant_name ${name}_frequencied.bed
java -Xmx30G -jar /mgh/scripts/gCNV_helper.jar filter ${name}_frequencied.bed ${name}_filtered.bed
java -Xmx30G -jar /mgh/scripts/gCNV_helper.jar annotateWithGenes any ${gtf} ${name}_filtered.bed ${name}_intermediate1.bed svtype
java -Xmx30G -jar /mgh/scripts/gCNV_helper.jar countExons ${name}_intermediate1.bed genes_any_overlap ${gtf} ${name}_intermediate2.bed
java -Xmx30G -jar /mgh/scripts/gCNV_helper.jar annotateWithGenes strict ${gtf} ${name}_intermediate2.bed ${name}_intermediate3.bed svtype
java -Xmx30G -jar /mgh/scripts/gCNV_helper.jar countExons ${name}_intermediate3.bed genes_strict_overlap ${gtf} ${name}_annotated.bed
```

${name}_annotated.bed is the final processed callset. EVerything following is optional QC

# optional , 
look at aneuploidies. First need to download the ploidy information
input is manifest file
```{sh}
#!/bin/bash
cut -f2 sample_set_entity.tsv | tr "," "\n" | grep -o -P "gs://.*tar.gz" > contig-ploidy-calls.txt

input_file=contig-ploidy-calls.txt
wcl=$(wc -l ${input_file} | cut -d " " -f1)
echo $wcl


for i in $(seq 1 ${wcl})
do
        file=$(sed ''${i}'!d' ${1})
        echo ${file}
        mkdir "ploidy_file_${i}"
        gsutil cp ${file} "./ploidy_file_${i}/ploidy_file_${i}.tar.gz"
done

for d in $(ls -d ploidy*/)
do
echo $d
cd $d
tar -xf *tar.gz
cd ..
```


Get ploidy conunts
```{r}
wd <- ""
ploidy_files <- list.files(paste0(wd), pattern="contig_ploidy.tsv", recursive = TRUE, full.names = TRUE)

ploidy_dfs <- lapply(ploidy_files, function(x){
  df <- read.table(x, comment.char = "@", header=TRUE, stringsAsFactors=FALSE, quote="", fill=TRUE)
  df$sample <- str_extract_all(scan(x, what="character", sep="\n", nlines=1, quiet=TRUE)[[1]], "(?<=SM:).*")[[1]]
  return(df)
})
ploidy_df <- do.call(rbind, ploidy_dfs)

ploidy_samples_df <- ploidy_df[ploidy_df$PLOIDY > 2 & ploidy_df$CONTIG != "chrX", ]
write.table(ploidy_samples_df, "aneuploidy_samples.tsv", sep="\t", col.names = TRUE, row.names = FALSE, quote=FALSE)
```

Download DCR files
```{r}
# This will take a while, you might want to subset to files with aneuploidies
system2("java", sprintf("-Xmx16G -jar %s getBarcodeCounts %ssample_set_entity.tsv %s/ploidy/ denoised_copy_ratios", jar_path, wd, wd ))
```


Plot ploidy counts,
```{r}
# wd <- "C:/Users/iwong/Documents/MGH/IBD/final_output/dcr/"
dcr_files <- list.files(wd, pattern="denoised_copy_ratios-", recursive = TRUE, full.names = TRUE)
temp1 <- str_detect(dcr_files, paste0("(",paste(ploidy_samples, collapse=")|(") , ")")) 
temp2 <- dcr_files[temp1]

cluster <- makeCluster(detectCores()-1)
clusterExport(cl=cluster, varlist=c("temp2", "str_detect", "str_extract"))
dcr_dfs <- parLapply(cluster, temp2, function(x){
  lines <- scan(x, what="character", sep="\n", quiet=TRUE)
  df <- read.table(textConnection(lines), comment.char = "@", header=TRUE, stringsAsFactors=FALSE, quote="", fill=TRUE)
  df$sample <- str_extract(lines[str_detect(lines, "SM:")], "(?<=SM:).*")[[1]]
  return(df)
})
stopCluster(cluster)
dcr_df <- do.call(rbind, dcr_dfs)

#plot linear copy ratio over chromosome for autosomes
autosome_ploidy_dfs <- ploidy_df[ploidy_df$PLOIDY!=2 & (ploidy_df$sample %in% autosome_ploidy_samples) & !str_detect(ploidy_df$CONTIG, "X|Y"), ]
for(i in 1:nrow(autosome_ploidy_dfs)){
  df <- dcr_df[dcr_df$sample==autosome_ploidy_dfs$sample[i] & dcr_df$CONTIG==autosome_ploidy_dfs$CONTIG[i], ]
  print(plot_ploidy(df))
  pdf(sprintf("%sploidy_sample_%s_%s.pdf", wd, df$sample[1], df$CONTIG[1]))
  my_plot <- plot_ploidy(df)
  print(my_plot)
  dev.off()
}

sex_ploidy_dfs <- ploidy_df[(ploidy_df$sample %in% sex_ploidy_samples) & str_detect(ploidy_df$CONTIG, "X|Y"), ]
df_instances <- rep("-1", unique(sex_ploidy_dfs$sample) %>% length)
for(i in seq_along(unique(sex_ploidy_dfs$sample))){
  par(mfrow=c(1,2))
  df <- dcr_df[dcr_df$sample==unique(sex_ploidy_dfs$sample)[i], ]
  # plot_x <- plot_ploidy(df[str_detect(df$CONTIG, "X"),])
  # plot_y <- plot_ploidy(df[str_detect(df$CONTIG, "Y"),])
  # grid.arrange(plot_x, plot_y, ncol=2)
  
  temp_df_x <- df[str_detect(df$CONTIG, "X"),]
  temp_df_y <- df[str_detect(df$CONTIG, "Y"),]
  df_instances[i] <- c(
                          rep(temp_df_x$CONTIG[1], ploidy_df[ploidy_df$CONTIG==temp_df_x$CONTIG[1] & ploidy_df$sample==temp_df_x$sample[1],]$PLOIDY[1]),
                          rep(temp_df_y$CONTIG[1], ploidy_df[ploidy_df$CONTIG==temp_df_y$CONTIG[1] & ploidy_df$sample==temp_df_y$sample[1],]$PLOIDY[1])
                          ) %>% paste0(collapse = "")
# 
#   my_plot <- arrangeGrob(plot_x, plot_y, ncol=2)
#   ggsave(sprintf("%s/dcr_plots/ploidy_sample_%s_sex_chroms.pdf", wd, df$sample[1]), my_plot)
}
```


Main Figures
variant count boxplots
```{r}
wd <- ""
gcnv <- read(wd, "_annotated.bed")
ploidy_samples <- read.table("aneuploidy_samples.tsv", sep="\t", header=TRUE)

qs_window <- seq(0, 100, 10)
total_variants <- rep(0, length(qs_window))
variant_counts <- vector("list", length(qs_window))

for(i in seq_along(qs_window)){
  filtered_qs <- gcnv$QS >= qs_window[i]
  filtered_vafs <- gcnv$vaf <= 0.01
  filtered <- gcnv[filtered_qs & filtered_vafs ,]
  total_variants[i] <- length(unique(filtered$name))
  variant_counts[[i]] <- as.numeric(table(filtered$sample))
}

n_outliers <- lapply(variant_counts, function(x) length(boxplot(x, plot=FALSE)$out) )

lengths <- sapply(variant_counts, length)
labels <- lapply(seq_along(qs_window), function(x){rep(qs_window[x], lengths[x])}) %>% unlist %>% as.character()

temp1 <- letters[seq_along(qs_window)]
labels2 <- lapply(seq_along(temp1), function(x){rep(temp1[x], lengths[x])}) %>% unlist
df <- data.frame(qs_threshold=labels, n_variants=unlist(variant_counts), class=labels2)
df$qs_threshold <- factor(df$qs_threshold, levels=qs_window)

df$n_variants_log2 <- (df$n_variants) %>% log2
df$n_variants_log10 <- df$n_variants %>% log10

gcnvhq <- gcnv[gcnv$HIGH_QUALITY, ]
write.table(gcnvhq, paste0(wd, "gcnv_HQ.tsv"), sep="\t", row.names = FALSE, col.names = TRUE, quote=FALSE)
```

# failure rate per batch
```{r}
df00 <- gcnv
df00 <- df00[match(unique(df00$sample), df00$sample), ]
df00$batch <- df00$name %>% str_extract_all("(A|B)_\\d*(?=_)") %>% unlist
batchToSample <- HashMap$new()
batchToSample$populate_append(df00, "batch", "sample")
sampleToPassRaw <- HashMap$new()
sampleToPassHQ <- HashMap$new()
sampleToPassFinal <- HashMap$new()
sampleToPassRaw$populate(df00, "sample", "lt100_raw_calls")
sampleToPassHQ$populate(df00, "sample", "lt10_highQS_rare_calls")
sampleToPassFinal$populate(df00, "sample", "PASS_SAMPLE")

batches <- df00$batch %>% u 
perBatchRate <- lapply(batches, function(B) {
  bool_passRaw <- lapply(batchToSample$get(B), function(S) {
    sampleToPassRaw$get(S)
  }) %>% unlist
  bool_passHQ <- lapply(batchToSample$get(B), function(S) {
    sampleToPassHQ$get(S)
  }) %>% unlist
  bool_passFinal <- lapply(batchToSample$get(B), function(S) {
    sampleToPassFinal$get(S)
  }) %>% unlist
  perc_raw <- length(which(bool_passRaw))/length(bool_passRaw)
  perc_hq <- length(which(bool_passHQ))/length(bool_passHQ) 
  perc_final <- length(which(bool_passFinal))/length(bool_passFinal)
  return(c(B, perc_raw, perc_hq, perc_final))
}) %>% do.call(rbind, .) %>% as.data.frame(stringsAsFactors=FALSE)
colnames(perBatchRate) <- c("batch", "raw", "HQ", "all")
for(i in 2:4){
  perBatchRate[, i] <- (perBatchRate[, i] %>% as.numeric() %>% round(digits = 4)) * 100
}

perBatchRate$N <- lapply(perBatchRate$batch, function(x){
  batchToSample$get(x) %>% length
}) %>% unlist

length(which(df00$PASS_SAMPLE)) / nrow(df00)
1 - length(which(df00$PASS_SAMPLE)) / nrow(df00)

perBatchRate <- perBatchRate[order(perBatchRate$all, decreasing = TRUE), ]

lm_eqn <- function(df){
    m <- lm(all ~ N, df);
    eq <- substitute(italic(y) == a + b %.% italic(x)*","~~italic(r)^2~"="~r2, 
         list(a = format(unname(coef(m)[1]), digits = 2),
              b = format(unname(coef(m)[2]), digits = 2),
             r2 = format(summary(m)$r.squared, digits = 3)))
    as.character(as.expression(eq));
}

g0 <- ggplot(perBatchRate, aes(x=N, y=all)) + 
  geom_point() + 
  xlab("N samples per batch") + 
  ylab("sample pass rate (%)") + 
  ggtitle("per batch sample failure rate") +
  theme(plot.title = element_text(hjust = 0.5)) +
  stat_summary(fun.data= mean_cl_normal) + 
  geom_smooth(method='lm') + 
  geom_text(x = 3000, y = 92.5, label = lm_eqn(perBatchRate), parse = TRUE)

g0

write.table(perBatchRate, "per_batch_failure_rate.tsv", sep="\t", col.names = TRUE, row.names = FALSE, quote=FALSE)
```


```{r}
g1 <- ggplot(df, aes(x=qs_threshold, y=n_variants)) +
  geom_boxplot(outlier.size = NA, outlier.shape = NA, color=wes_palette("Zissou1")[1], fill=wes_palette("Zissou1")[2], alpha=0.6) + 
  coord_cartesian(ylim = c(0, 40)) +
  xlab("QS threshold") + 
  ylab("# of Variants per sample") +
  ggtitle("Variants per sample, outliers not shown") +
  theme(plot.title = element_text(hjust = 0.5))
g1
```


```{r}
g2 <- ggplot(df[df$qs_threshold!=0 & df$qs_threshold!=10,], aes(x=qs_threshold, y=n_variants)) +
  geom_boxplot(outlier.size = NA, outlier.shape = NA, color=wes_palette("Zissou1")[1], fill=wes_palette("Zissou1")[2], alpha=0.6) + 
  coord_cartesian(ylim = c(0, 16)) +
  xlab("QS threshold") + 
  ylab("# of Variants per sample") +
  ggtitle("Variants per sample, outliers not shown") +
  theme(plot.title = element_text(hjust = 0.5))
g2
```

variant count histograms
```{r}
g3 <- ggplot(df[df$qs_threshold==0,] , aes(x=n_variants_log2)) +
  geom_histogram(aes(y=..density..), colour="BLACK", fill=wes_palette("FantasticFox1")[1]) + 
  geom_density(alpha=.2, bw=0.3, size=1, color=wes_palette("FantasticFox1")[5]) +
  ylab("frequency") + 
  xlab("number of variants") +
  ggtitle(bquote(~log[2]~"transformed number of variants; QS threshold=0 ")) +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_x_continuous(breaks=0:10, labels=2^(0:10))
g3
```

```{r}
bks <- seq(0, 10, 0.6)
g4 <- ggplot(df[df$qs_threshold==50,] , aes(x=n_variants_log2)) +
  geom_histogram(aes(y=..density..), colour="BLACK", fill=wes_palette("FantasticFox1")[1], breaks=bks) + 
  geom_density(alpha=.2, bw=0.5, size=1, color=wes_palette("FantasticFox1")[5]) +
  ylab("frequency") + 
  xlab("number of variants") +
  ggtitle(bquote(~log[2]~"transformed number of variants; QS threshold=50 ")) +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_x_continuous(breaks=0:10, labels=2^(0:10))
g4
```


```{r}
bks <- seq(0, 10, 0.6)
g5 <- ggplot(df[df$qs_threshold==100,] , aes(x=n_variants_log2)) +
  geom_histogram(aes(y=..density..), colour="BLACK", fill=wes_palette("FantasticFox1")[1], breaks=bks) + 
  geom_density(alpha=.2, bw=0.9, size=1, color=wes_palette("FantasticFox1")[5]) +
  ylab("frequency") + 
  xlab("number of variants") +
  ggtitle(bquote(~log[2]~"transformed number of variants; QS threshold=100 ")) +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_x_continuous(breaks=0:10, labels=2^(0:10))
g5
```



number of variants vs number of exons
```{r}
cohort_name <- ""
if(FALSE){
  qual_type <- "raw"
  dup_count <- gcnv[gcnv$svtype=="DUP" & gcnv$chr!="chrX" & gcnv$chr!="chrY" & gcnv$genes_any_overlap_totalExons!="NA", ]
  del_count <- gcnv[gcnv$svtype=="DEL" & gcnv$chr!="chrX" & gcnv$chr!="chrY" & gcnv$genes_any_overlap_totalExons!="NA", ]  
  nvarps <- c(0, 6)
} else {
  qual_type <- "HQ"
  dup_count <- gcnv[gcnv$svtype=="DUP" & gcnv$HIGH_QUALITY & gcnv$chr!="chrX" & gcnv$chr!="chrY" & gcnv$genes_any_overlap_totalExons!="NA", ]
  del_count <- gcnv[gcnv$svtype=="DEL" & gcnv$HIGH_QUALITY & gcnv$chr!="chrX" & gcnv$chr!="chrY" & gcnv$genes_any_overlap_totalExons!="NA", ]  
  nvarps <- c(0, 0.9)
}

if(FALSE){
  ploidy_samples_df <- read.table("C:/Users/iwong/Documents/MGH/ukbb/08_QC/aneuploidy_samples.tsv", sep="\t", header=TRUE)
  list_by_aneu_bool_to_remove <- lapply(seq_down(ploidy_samples_df), function(x) {
    bool_same_sample <- gcnv$sample == ploidy_samples_df$sample[x]
    bool_same_chr <- gcnv$chr == ploidy_samples_df$CONTIG[x]
    return(as.integer(bool_same_sample & bool_same_chr))
  })
  bool_df <- list2DF(list_by_aneu_bool_to_remove)
  bool_to_keep <- rowSums(bool_df) == 0
  gcnv <- gcnv[bool_to_keep, ]
} else{
  
}

del_count$n_exons <- del_count$genes_any_overlap_totalExons
dup_count$n_exons <- dup_count$genes_any_overlap_totalExons

del_count <- del_count[del_count$n_exons >= 4, ]
dup_count <- dup_count[dup_count$n_exons >= 4, ]

unique_dup <- dup_count
unique_del <- del_count

exon_table_dup <- table(unique_dup$n_exons)
exon_table_del <- table(unique_del$n_exons)

df_dup <- data.frame(nexons=names(exon_table_dup) %>% as.numeric(), nvariants=as.numeric(exon_table_dup))
df_dup <- df_dup[order(df_dup$nexons, decreasing = FALSE),]
for(i in seq(nrow(df_dup)-1, 1, -1)){
  df_dup$nvariants[i] = df_dup$nvariants[i] + df_dup$nvariants[i+1]
}

df_del <- data.frame(nexons=names(exon_table_del) %>% as.numeric(), nvariants=as.numeric(exon_table_del))
df_del <- df_del[order(df_del$nexons, decreasing = FALSE),]
for(i in seq(nrow(df_del)-1, 1, -1)){
  df_del$nvariants[i] = df_del$nvariants[i] + df_del$nvariants[i+1]
}

df_del$type <- "DEL"
df_dup$type <- "DUP"
df <- rbind(df_del, df_dup)
df$log2_nvars <- log2(df$nvariants)
df$log2_nexons <- log2(df$nexons)
df$nvariants_per_sample <- df$nvariants / lu(gcnv$sample)

# singletons
singletons_del <- which(table(del_count$variant_name[!del_count$sample %in% ploidy_samples])==1) %>% names
df_single_del <- del_count[del_count$variant_name %in% singletons_del, ]
exon_table_single_del <- table(df_single_del$n_exons)
exon_table_del <- table(del_count$n_exons)
df_del <- data.frame(nexons=names(exon_table_del) %>% as.numeric(), nvariants=as.numeric(exon_table_del))
df_del <- df_del[order(df_del$nexons, decreasing = FALSE),]
df1_del <- data.frame(nexons=names(exon_table_single_del) %>% as.numeric(), nvariants_single=as.numeric(exon_table_single_del))
df1_del <- df1_del[order(df1_del$nexons, decreasing = FALSE),]
df2_del <- merge(df_del, df1_del)
for(i in seq(nrow(df2_del)-1, 1, -1)){
  df2_del$nvariants[i] = df2_del$nvariants[i] + df2_del$nvariants[i+1]
  df2_del$nvariants_single[i] = df2_del$nvariants_single[i] + df2_del$nvariants_single[i+1]
}
df2_del$proportion <- df2_del$nvariants_single/df2_del$nvariants*100
df2_del$type <- "DEL"

singletons_dup <- which(table(dup_count$variant_name[!dup_count$sample %in% ploidy_samples])==1) %>% names
df_single_dup <- dup_count[dup_count$variant_name %in% singletons_dup, ]
exon_table_single_dup <- table(df_single_dup$n_exons)
exon_table_dup <- table(dup_count$n_exons)
df_dup <- data.frame(nexons=names(exon_table_dup) %>% as.numeric(), nvariants=as.numeric(exon_table_dup))
df_dup <- df_dup[order(df_dup$nexons, decreasing = FALSE),]
df1_dup <- data.frame(nexons=names(exon_table_single_dup) %>% as.numeric(), nvariants_single=as.numeric(exon_table_single_dup))
df1_dup <- df1_dup[order(df1_dup$nexons, decreasing = FALSE),]
df2_dup <- merge(df_dup, df1_dup)
for(i in seq(nrow(df2_dup)-1, 1, -1)){
  df2_dup$nvariants[i] = df2_dup$nvariants[i] + df2_dup$nvariants[i+1]
  df2_dup$nvariants_single[i] = df2_dup$nvariants_single[i] + df2_dup$nvariants_single[i+1]
}
df2_dup$proportion <- df2_dup$nvariants_single/df2_dup$nvariants*100
df2_dup$type <- "DUP"

df3 <- rbind(df2_del, df2_dup)
df3$log2_nexons <- df3$nexons %>% log2
```


```{r}
g6.1 <- ggplot(data=df, aes(x=log2_nexons, y=nvariants, group=type)) +
  geom_line(aes(colour=type), size=1.5) +
  scale_color_manual(values=c(wes_palette("FantasticFox1")[5], wes_palette("FantasticFox1")[3])) +
  theme(legend.position="bottom") + 
  scale_x_continuous(breaks=0:12, labels=2^(0:12)) +
  xlab("number of exons") + 
  ylab(paste0("number of ",qual_type ," variants")) + 
  ggtitle(paste0(cohort_name, ", Distribution of ",qual_type ," CNVs"))  +
  coord_cartesian(xlim=c(2,12))
g6.2 <- ggplot(data=df, aes(x=log2_nexons, y=nvariants_per_sample, group=type)) +
  geom_line(aes(colour=type), size=1.5) +
  scale_color_manual(values=c(wes_palette("FantasticFox1")[5], wes_palette("FantasticFox1")[3])) +
  theme(legend.position="bottom") + 
  scale_x_continuous(breaks=0:12, labels=2^(0:12)) +
  xlab("number of exons") + 
  ylab(paste0("number of ",qual_type ," variants per sample")) + 
  ggtitle(paste0(cohort_name, ", Distribution of ",qual_type ," CNVs per sample"))  +
  coord_cartesian(xlim=c(2,12), ylim=nvarps)
g6.1
g6.2
```

```{r}
g7 <- ggplot(data=df3[df3$nexons<5000  , ], aes(x=log2_nexons, y=proportion, group=type)) +
  geom_line(aes(colour=type), size=1.5) +
  scale_color_manual(values=c(wes_palette("FantasticFox1")[5], wes_palette("FantasticFox1")[3])) +
  theme(legend.position="bottom") + 
  scale_x_continuous(breaks=0:12, labels=2^(0:12)) +
  xlab("number of exons") + 
  ylab("percent of singletons") + 
  ggtitle(paste0(cohort_name, ", Distribution of ", qual_type, " CNVs, no chrX")) + 
  ylim(0, 100) 
g7
```



overlapping histogram of size
```{r}
df <- gcnv[, c("start", "end", "svtype", "PASS_FREQ", "PASS_SAMPLE", "PASS_QS")]
df$size <- (df$end - df$start)/1000
df$size_log10 <- df$size %>% log10
df$size_log2 <- df$size %>% log2
df$HQ <- df$PASS_FREQ & df$PASS_QS & df$PASS_SAMPLE
```


```{r}
g8 <- ggplot(data=df[df$size>0.125 & df$size<1500, ], aes(x=size_log2, fill=svtype)) +
  geom_histogram(alpha=0.7, position = "identity", aes(y = ..density..)) +
  scale_fill_manual(values=c(wes_palette("FantasticFox1")[5], wes_palette("FantasticFox1")[3])) +
  scale_x_continuous(breaks=-4:10, labels = 2^(-4:10)) + 
  xlab("CNV size (KB)") + 
  ggtitle("Raw CNV size distribution") 
g8
```

```{r}
g9 <- ggplot(data=df[df$size>0.125 & df$size<1500 & df$HQ, ], aes(x=size_log2, fill=svtype)) +
  geom_histogram(alpha=0.7, position = "identity", aes(y = ..density..)) +
  scale_fill_manual(values=c(wes_palette("FantasticFox1")[5], wes_palette("FantasticFox1")[3])) +
  scale_x_continuous(breaks=-4:10, labels = 2^(-4:10)) + 
  xlab("CNV size (KB)") + 
  ggtitle("HQ CNV size distribution")
g9
```

dist of hq calls
the proportion of samples with 0, 1, 2, 3, 4, and >4 HQ CNVs, and for each value on the X axi
```{r}
ASC <- read.table("ASC_benchmark_callset.bed", sep="\t", header=TRUE)
asc_hq <- ASC[ASC$HIGH_QUALITY, ]
gcnv_hq <- gcnv[gcnv$HIGH_QUALITY, ]

no_hq_asc <-ASC$sample[!ASC$sample %in% asc_hq$sample] %>% lu
no_hq_gcnv <-gcnv$sample[!gcnv$sample %in% gcnv_hq$sample] %>% lu

temp0 <- srt(asc_hq$sample) %>% srt %>% as.data.frame(stringsAsFactors=FALSE)
temp0$x <- temp0$x %>% as.integer()
temp0$Cohort <- "ASD"
gte_10 <- data.frame(x = 10, Freq = sum(temp0$x[temp0$x >= 10]), Cohort="ASD", stringsAsFactors = FALSE)
eq_0 <- data.frame(x = 0, Freq = no_hq_asc, Cohort="ASD", stringsAsFactors = FALSE)
temp0 <- temp0[temp0$x < 10, ]
temp0 <- rbind(temp0, gte_10, eq_0)
temp0 <- temp0[order(temp0$x, decreasing = FALSE), ]
temp0$prop <- temp0$Freq / sum(temp0$Freq) * 100
temp0$cum_prop <- cumsum(temp0$Freq) / sum(temp0$Freq)


temp1 <- srt(gcnv_hq$sample) %>% srt %>% as.data.frame(stringsAsFactors=FALSE)
temp1$x <- temp1$x %>% as.integer()
temp1$Cohort <- "EPI"
gte_10 <- data.frame(x = 10, Freq = sum(temp1$x[temp1$x >= 10]), Cohort="EPI", stringsAsFactors = FALSE)
eq_0 <- data.frame(x = 0, Freq = no_hq_gcnv, Cohort="EPI", stringsAsFactors = FALSE)
temp1 <- temp1[temp1$x < 10, ]
temp1 <- rbind(temp1, gte_10, eq_0)
temp1 <- temp1[order(temp1$x, decreasing = FALSE), ]
temp1$prop <- temp1$Freq / sum(temp1$Freq) * 100
temp1$cum_prop <- cumsum(temp1$Freq) / sum(temp1$Freq)

temp2 <- rbind(temp0, temp1)
temp2$cum_prop <- temp2$cum_prop * 100

g10 <- ggplot(temp2, aes(x=x, y = prop, fill=Cohort)) + 
  geom_bar(position = "dodge", stat="identity") + 
  scale_x_continuous(breaks = 0:10, labels = c(0:9, "10+")) + 
  scale_y_continuous(breaks = seq(0, 40, 10)) + 
  ylab("Percent of samples") + 
  xlab("Number of HQ CNVs")
g11 <- ggplot(temp2, aes(x = x, y = cum_prop)) +
  geom_line(aes(colour=Cohort), size=2) +
  scale_x_continuous(breaks = 0:10, labels = c(0:9, "10+")) + 
  scale_y_continuous(breaks = seq(0, 100, 10)) + 
  ylab("Percent of samples") + 
  xlab("Cumulative Number of HQ CNVs")
```






